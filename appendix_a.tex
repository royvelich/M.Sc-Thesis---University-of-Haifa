\chapter{Polynomial Approximation}
\label{appendix:a}
\section{Piece-wise Polynomial Periodic Function}
To make each Newton's method iteration more computationally efficient, and to simplify the gradient and Hessian derivations and the technical implementation details in general, we design a smooth periodic function $f_p: \mathbb{R} \xrightarrow[]{} \mathbb{R}$ with period $p$, that satisfies the following requirements for any $x \in \mathbb{R}$ and $k \in \mathbb{Z}$:
\begin{equation}\label{eq:periodic_req}
\begin{split}
&0 \leq f_p\left(x\right) \leq 1 \\
&f_p\left(x\right) = f_p\left(x + kp\right) \\
&f_p\left(\frac{p}{2} + kp\right) = 1 \\
&f_p\left(kp\right) = 0 \\
\end{split}
\end{equation}
In other words, we simply want its roots to be periodic. We achieve it by finding a polynomial $g\left(x\right)$ that satisfies requirements \ref{eq:periodic_req} in the interval $\left[0, p\right]$, and replicating it over the whole real-numbers domain. Explicitly, we want the polynomial to satisfy the following:
\begin{equation}\label{eq:system_of_equations}
\begin{split}
&g\left(0\right) = 0, \quad,
g\left(\frac{p}{2}\right) = 1, \quad,
g\left(p\right) = 0 \\ \\
&\frac{dg}{dx}\left(0\right) = 0, \quad
\frac{dg}{dx}\left(\frac{p}{2}\right) = 0, \quad
\frac{dg}{dx}\left(p\right) = 0
\end{split}
\end{equation}
This suggest that $g\left(x\right)$ is a polynomial of degree 6. Therefore, $g\left(x\right)$ is given by:
\begin{equation}\label{eq:polynomial_6}
\begin{split}
g\left(x\right) = a_0 + a_1x + a_2x^2 + a_3x^3 + a_4x^4 + a_5x^5 = a^T \cdot \mathrm{x}\left(x\right)
\end{split}
\end{equation}
Where $a = \left(a_0,a_1,a_2,a_3,a_4,a_5\right)^T$ and $\mathrm{x}\left(x\right) = \left(1,x,x^2,x^3,x^4,x^5\right)^T$.
Solving the linear system of equations \ref{eq:system_of_equations} yields the desired coefficients vector $a_* = \left(a^*_0,a^*_1,a^*_2,a^*_3,a^*_4,a^*_5\right)^T$. Therefore, we define $f_p\left(x\right)$ as follows:
\begin{equation}\label{eq:polynomial_6}
\begin{split}
f_p\left(x\right) = 
\begin{cases} 
  g_*\left(x\right) & x \in \left[0,p\right] \\
  g_*\left(x \mod{p}\right) & x \notin \left[0,p\right]
\end{cases}
\end{split}
\end{equation}
Where $g_*\left(x\right) = a_*^T \cdot \mathrm{x}\left(x\right)$. We call $f_p\left(x\right)$ a \emph{piece-wise polynomial periodic function}. Figure \ref{fig:polynomial_periodic_function} visualize $f_p\left(x\right)$ for an arbitrary period.
\begin{figure}[ht]
\centering
\includegraphics[width=12cm]{figures/periodic_function.png}
\caption[Piece-wise Polynomial Periodic Function]{A plot of $f_p\left(x\right)$ in the interval $\left[-3p, 3p\right]$. As can be seen, $f_p\left(x\right)$ is a priodic function, where its roots are equally spaced with a distance $p$.}
\label{fig:polynomial_periodic_function}
\end{figure}
\section{First Derivative}
The first derivative of $g_*\left(x\right)$ is given by:
\begin{equation}\label{eq:polynomial_6}
\begin{split}
g'_*\left(x\right) = a^*_1 + 2a^*_2x + 3a^*_3x^2 + 4a^*_4x^3 + 5a^*_5x^4 = b_*^T \cdot \mathrm{x}\left(x\right)
\end{split}
\end{equation}
Where $b_* = \left(a^*_1,2a^*_2,3a^*_3,4a^*_4,5a^*_5,0\right)^T$ and $\mathrm{x}\left(x\right) = \left(1,x,x^2,x^3,x^4,x^5\right)^T$. Therefore, we define $f'_p\left(x\right)$ is given as follows:
\begin{equation}\label{eq:polynomial_6}
\begin{split}
f'_p\left(x\right) = 
\begin{cases} 
  g'_*\left(x\right) & x \in \left[0,p\right] \\
  g'_*\left(x \mod{p}\right) & x \notin \left[0,p\right]
\end{cases}
\end{split}
\end{equation}
\section{Second Derivative}
The second derivative of $g_*\left(x\right)$ is given by:
\begin{equation}\label{eq:polynomial_6}
\begin{split}
g''_*\left(x\right) = 2a^*_2 + 6a^*_3x + 12a^*_4x^2 + 20a^*_5x^3 = c_*^T \cdot \mathrm{x}\left(x\right)
\end{split}
\end{equation}
Where $c_* = \left(2a^*_2,6a^*_3, 12a^*_4,20a^*_5,0,0\right)^T$ and $\mathrm{x}\left(x\right) = \left(1,x,x^2,x^3,x^4,x^5\right)^T$. Therefore, we define $f''_p\left(x\right)$ is given as follows:
\begin{equation}\label{eq:polynomial_6}
\begin{split}
f''_p\left(x\right) = 
\begin{cases} 
  g''_*\left(x\right) & x \in \left[0,p\right] \\
  g''_*\left(x \mod{p}\right) & x \notin \left[0,p\right]
\end{cases}
\end{split}
\end{equation}
\chapter{Gradient and Hessian Derivations}
In this appendix, we show detailed derivations for the gradient and Hessian of each individual penalty function, as defined in chapter \ref{chapter:method}.
\section{Composition - General Case}
\label{section:composition_general_case}
Given two smooth functions $f: \mathbb{R}^m \xrightarrow[]{} \mathbb{R}$ and $h: \mathbb{R}^n \xrightarrow[]{} \mathbb{R}^m$, we derive the gradient and Hessian of their composition $g\left(x\right) = f \circ h \left(x\right)$.
\subsection{Gradient}
The differential of  $g\left(x\right)$ is computed as follows:
\begin{flalign}
dg\left(x\right) &= d\bigg(f\Big(h\left(x\right)\Big)\bigg) \\ &= \nabla f\Big(h\left(x\right)\Big)^T \cdot dh\left(x\right)
\\
& = \nabla f \Big(h\left(x\right)\Big)^T \cdot J_h\left(x\right) \cdot dx
\\
& = \bigg(J_h\left(x\right)^T \cdot \nabla f\Big(h\left(x\right)\Big)\bigg)^T \cdot dx \label{eq:generalized_composition_gradient}
\end{flalign}
By \ref{eq:generalized_composition_gradient} we get that the gradient $\nabla g\left(x\right)$ is given by:
\begin{flalign}
\nabla g\left(x\right) = J_h\left(x\right)^T \cdot \nabla f\Big(h\left(x\right)\Big)
\end{flalign}
Where $J_h\left(x\right)$ is the Jacobian matrix of $h$ at $x$.
\subsection{Hessian}
The differential of $\nabla g\left(x\right)$ is computed as follows:
\begin{flalign}
d \nabla g \left(x\right) &= d\bigg( J_h\left(x\right)^T \cdot \nabla f\Big(h\left(x\right)\Big) \bigg)
\\
&= d J_h\left(x\right)^T \cdot \nabla f\Big(h\left(x\right)\Big) + J_h\left(x\right)^T \cdot d \nabla f\Big(h\left(x\right)\Big)
\\
&= \Big(d J_h\left(x\right)\Big)^T \cdot \nabla f\Big(h\left(x\right)\Big) + J_h\left(x\right)^T \cdot d \nabla f\Big(h\left(x\right)\Big)
\\
&= \Big(T_h\left(x\right)dx\Big)^T \cdot \nabla f\Big(h\left(x\right)\Big) + J_h\left(x\right)^T \cdot \nabla^2 f\Big(h\left(x\right)\Big) \cdot dh\left(x\right)
\\
&= dx^T \cdot T_h\left(x\right)^T \cdot \nabla f\Big(h\left(x\right)\Big) + J_h\left(x\right)^T \cdot \nabla^2 f\Big(h\left(x\right)\Big) \cdot J_h\left(x\right) \cdot dx
\\
&= \bigg(T_h\left(x\right)^T \cdot \nabla f\Big(h\left(x\right)\Big)\bigg)^T \cdot dx + J_h\left(x\right)^T \cdot \nabla^2 f\Big(h\left(x\right)\Big) \cdot J_h\left(x\right) \cdot dx
\\
&= \underbrace{\nabla f\Big(h\left(x\right)\Big)^T \cdot T_h\left(x\right)}_{\text{$n \times n$ matrix}} \cdot dx + \underbrace{J_h\left(x\right)^T \cdot \nabla^2 f\Big(h\left(x\right)\Big) \cdot J_h\left(x\right)}_{\text{$n \times n$ matrix}} \cdot dx
\\
&= \bigg( \nabla f\Big(h\left(x\right)\Big)^T \cdot T_h\left(x\right) + J_h\left(x\right)^T \cdot \nabla^2 f\Big(h\left(x\right)\Big) \cdot J_h\left(x\right) \bigg) \cdot dx
\label{eq:generalized_composition_hessian}
\end{flalign}
By \ref{eq:generalized_composition_hessian} we get that the Hessian $\nabla^2 g\left(x\right)$ is given by:
\begin{flalign}
\nabla^2 g \left(x\right) = \nabla f\Big(h\left(x\right)\Big)^T \cdot T_h\left(x\right) + J_h\left(x\right)^T \cdot \nabla^2 f\Big(h\left(x\right)\Big) \cdot J_h\left(x\right)
\end{flalign}
Where $T_h\left(x\right)$ is a tensor of $n$ matrices, each of size $m \times n$.
\subsection{Derivation of $T_h\left(x\right)$}
Let the components of $h\left(x\right)$ be defined as follows:
\begin{flalign}
    h\left(x\right) &= \begin{bmatrix}
           h_1\left(x\right) \\
           \vdots \\
           h_m\left(x\right)
         \end{bmatrix}
\end{flalign}
Such that $h_i\left(x\right): \mathbb{R}^n \xrightarrow[]{} \mathbb{R}$ for $i \in \left\{1,2,\hdots,m\right\}$. Using that explicit definition of $h\left(x\right)$, we get that the Jacobian $J_h\left(x\right)$ is given by:
\begin{flalign}
    J_h\left(x\right) &= \begin{bmatrix}
           \nabla h_1\left(x\right)^T \\
           \vdots \\
           \nabla h_m\left(x\right)^T
         \end{bmatrix}
\end{flalign}
The differential of $J_h\left(x\right)$ is given as follows:
\begin{flalign}
    dJ_h\left(x\right) &= \begin{bmatrix}
           d\nabla h_1\left(x\right)^T \\
           \vdots \\
           d\nabla h_m\left(x\right)^T
         \end{bmatrix}
\\
    &= \begin{bmatrix}
               \Big(d\nabla h_1\left(x\right)\Big)^T \\
               \vdots \\
               \Big(d\nabla h_m\left(x\right)\Big)^T
             \end{bmatrix}
\\
    &= \begin{bmatrix}
               \Big(\nabla^2 h_1\left(x\right) \cdot dx\Big)^T \\
               \vdots \\
               \Big(\nabla^2 h_m\left(x\right) \cdot dx\Big)^T
             \end{bmatrix}
\end{flalign}
Let $\mathrm{row}_i\Big(\nabla^2 h_j\left(x\right)\Big)$ be a function that returns the $i$th row of a given matrix. Let $M_i\left(x\right)$ be a matrix of size $m \times n$ defined as follows:
\begin{flalign}
    M_i\left(x\right) &=
    \begin{bmatrix}
       \mathrm{row}_i\Big(\nabla^2 h_1\left(x\right)\Big) \\
       \vdots \\
       \mathrm{row}_i\Big(\nabla^2 h_m\left(x\right)\Big) \\
    \end{bmatrix}
\end{flalign}
We now can rewrite $dJ_h\left(x\right)$ as follows:
\begin{flalign}
    dJ_h\left(x\right) &=
    \begin{bmatrix}
       M_1\left(x\right) dx & \hdots & M_n\left(x\right) dx
    \end{bmatrix}
    \\
    &= 
    \begin{bmatrix}
       M_1\left(x\right) & \hdots & M_n\left(x\right)
    \end{bmatrix} dx \\
    &= 
    T_h\left(x\right) dx
\end{flalign}
Where $T_h\left(x\right) = \begin{bmatrix} M_1\left(x\right) & \hdots & M_n\left(x\right) \end{bmatrix}$.
\section{Composition - Degenerate Case}
Even though the following derivation is a private case of \ref{section:composition_general_case}, we include it as well for clarity. Given two smooth functions $f: \mathbb{R} \xrightarrow[]{} \mathbb{R}$ and $h: \mathbb{R}^n \xrightarrow[]{} \mathbb{R}$, we derive the gradient and Hessian of their composition $f \circ h\left(x\right)$.
\subsection{Gradient}
The differential of  $f\Big(h\left(x\right)\Big)$ is computed as follows:
\begin{flalign}
df\Big(h\left(x\right)\Big) &= f'\Big(h\left(x\right)\Big) \cdot dh\left(x\right)
\\
& = f'\Big(h\left(x\right)\Big) \cdot \nabla h\left(x\right)^T \cdot dx
\\
& = \bigg(f'\Big(h\left(x\right)\Big) \cdot \nabla h\left(x\right)\bigg)^T \cdot dx \label{eq:composition_gradient}
\end{flalign}
By \ref{eq:composition_gradient} we get that the gradient $\nabla f\Big(h\left(x\right)\Big)$ is given by:
\begin{flalign}
\nabla f\Big(h\left(x\right)\Big) = f'\Big(h\left(x\right)\Big) \cdot \nabla h\left(x\right)
\end{flalign}
\subsection{Hessian}
The differential of  $\nabla f\Big(h\left(x\right)\Big)$ is computed as follows:
\begin{flalign}
d \nabla f\Big(h\left(x\right)\Big) &= d\bigg( f'\Big(h\left(x\right)\Big) \cdot \nabla h\left(x\right)\bigg)
\\
& = df'\Big(h\left(x\right)\Big) \cdot \nabla h\left(x\right) + f'\Big(h\left(x\right)\Big) \cdot d\nabla h\left(x\right)
\\
& = f''\Big(h\left(x\right)\Big) \cdot dh\left(x\right) \cdot \nabla h\left(x\right) + f'\Big(h\left(x\right)\Big) \cdot \nabla^2 h\left(x\right) \cdot dx
\\
& = f''\Big(h\left(x\right)\Big) \cdot \underbrace{\nabla h\left(x\right)^T \cdot dx}_{\text{scalar}} \cdot \nabla h\left(x\right) + f'\Big(h\left(x\right)\Big) \cdot \nabla^2 h\left(x\right) \cdot dx
\\
& = f''\Big(h\left(x\right)\Big) \cdot \underbrace{\nabla h\left(x\right) \cdot \nabla h\left(x\right)^T}_{\text{matrix}} \cdot dx + f'\Big(h\left(x\right)\Big) \cdot \nabla^2 h\left(x\right) \cdot dx
\\
& = \bigg(f''\Big(h\left(x\right)\Big) \cdot \nabla h\left(x\right) \cdot \nabla h\left(x\right)^T + f'\Big(h\left(x\right)\Big) \cdot \nabla^2 h\left(x\right)\bigg) \cdot dx
\label{eq:composition_hessian}
\end{flalign}
By \ref{eq:composition_hessian} we get that the Hessian $\nabla^2 f\Big(h\left(x\right)\Big)$ is given by:
\begin{flalign}
\nabla^2 f\Big(h\left(x\right)\Big) = f''\Big(h\left(x\right)\Big) \cdot \nabla h\left(x\right) \cdot \nabla h\left(x\right)^T + f'\Big(h\left(x\right)\Big) \cdot \nabla^2 h\left(x\right)
\end{flalign}








\section{Squared Norm}
In this section, we derive the gradient and Hessian of the squared Euclidean norm $\norm{\cdot}_2^2: \mathbb{R}^n \xrightarrow[]{} \mathbb{R}$.
\subsection{Gradient}
The differential of $\norm{\cdot}_2^2$ is computed as follows:
\begin{flalign}
d\norm{x}_2^2 &= d\left(x^Tx\right) \\
&= \left(dx\right)^Tx + x^Tdx \\
&= x^Tdx + x^Tdx \\
&= 2x^Tdx \\
\label{eq:squared_norm_gradient}
&= \left(2x\right)^Tdx
\end{flalign}
By \ref{eq:squared_norm_gradient} we get that the gradient $\nabla \norm{x}_2^2$ is given by:
\begin{flalign}
\nabla \norm{x}_2^2 = 2x
\end{flalign}
\subsection{Hessian}
The differential of $\nabla \norm{\cdot}_2^2$ is computed as follows:
\begin{flalign}
d\norm{x}_2^2 &= d\left(x^Tx\right) \\
&= \left(dx\right)^Tx + x^Tdx \\
&= x^Tdx + x^Tdx \\
&= 2x^Tdx \\
\label{eq:squared_norm_gradient}
&= \left(2x\right)^Tdx
\end{flalign}
By \ref{eq:squared_norm_gradient} we get that the gradient $\nabla \norm{x}_2^2$ is given by:
\begin{flalign}
\nabla \norm{x}_2^2 = 2x
\end{flalign}




\section{Angle Penalty Function}
The angle penalty functions is given by:
\begin{equation}\label{eq:angle_penalty}
\begin{split}
P_{\mathrm{angle}}\left(e_i,e_j\right) = \mathrm{sin} \bigg( 4\Big(\theta\left(e_i\right) - \theta\left(e_j\right)\Big) - \frac{\pi}{2}\bigg) + 1
\end{split}
\end{equation}
Where $\theta\left(e_k\right) = \mathrm{atan2}\Big(\mathrm{y}\left(v_k^2\right) - \mathrm{y}\left(v_k^1\right), \mathrm{x}\left(v_k^2\right) - \mathrm{x}\left(v_k^1\right)\Big)$ is the angle formed by half-edge $e_k = \left(v^1_k, v^2_k\right)$ with the positive \emph{x-axis} direction, when treated as a vector based at $v_k^1$ and heading $v_k^2$, for $k \in \left\{i,j\right\}$.

\noindent By denoting:
\begin{equation}\label{eq:angle_penalty}
u = \Big(\mathrm{y}\left(v_i^2\right), \mathrm{y}\left(v_i^1\right), \mathrm{x}\left(v_i^2\right), \mathrm{x}\left(v_i^1\right), \mathrm{y}\left(v_j^2\right), \mathrm{y}\left(v_j^1\right), \mathrm{x}\left(v_j^2\right), \mathrm{x}\left(v_j^1\right)\Big)^T
\end{equation}
And by replacing the sine expression with a piece-wise polynomial periodic function $f_p$ with period $p=\frac{\pi}{2}$ (as defined in appendix \ref{appendix:a}), we can rewrite $P_{\mathrm{angle}}$ as follows:
\begin{equation}\label{eq:angle_penalty_rephrased}
\begin{split}
P_{\mathrm{angle}}\left(u\right) = f_{\frac{\pi}{2}} \bigg(h\left(u\right)\bigg)
\end{split}
\end{equation}
Where $h\left(u\right) = \alpha\left(u\right) - \beta\left(u\right)$, and $\alpha$ and $\beta$ are given by $\alpha\left(u\right) = \mathrm{atan2}\Big(u_0 - u_1, u_2 - u_3\Big)$ and $\beta\left(u\right) = \mathrm{atan2}\Big(u_4 - u_5, u_6 -u_7\Big)$.
\noindent Since we already know how to calculate the gradient and Hessian for a composition of smooth functions, we only need to find expressions for $\nabla h\left(u\right)$ and $\nabla^2 h\left(u\right)$.
\subsection{Gradient}
The differential of $h\left(u\right)$ is given by:
\begin{flalign}
dh\left(u\right) &= d\Big(\alpha\left(u\right) - \beta\left(u\right)\Big)
\\
&= \nabla\alpha\left(u\right)^T du - \nabla\beta\left(u\right)^T\ du
\\
\label{eq:gradient_h_angle}
&= \bigg(\nabla\alpha\left(u\right) - \nabla\beta\left(u\right)\bigg)^Tdu
\end{flalign}
By \ref{eq:gradient_h_angle} we get that the gradient $\nabla h\left(u\right)$ is given by:
\begin{equation}
\begin{split}
\nabla h\left(u\right) = \nabla\alpha\left(u\right) - \nabla\beta\left(u\right)
\end{split}
\end{equation}
The differential of $\alpha\left(x\right)$ is given by:
\begin{flalign*}
d\alpha\left(u\right) &= d\bigg(\mathrm{atan2}\Big(u_0 - u_1, u_2 - u_3\Big)\bigg) \\
&= \frac{d\mathrm{atan2}}{dy}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot d\big(u_0 - u_1\big) + \frac{d\mathrm{atan2}}{dx}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot d\big(u_2 - u_3\big) \\
&= \frac{d\mathrm{atan2}}{dy}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_0 - \nabla u_1\big)^Tdu + \frac{d\mathrm{atan2}}{dx}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_2 - \nabla u_3\big)^Tdu \\
&= \Bigg(\frac{d\mathrm{atan2}}{dy}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_0 - \nabla u_1\big)^T + \frac{d\mathrm{atan2}}{dx}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_2 - \nabla u_3\big)^T\Bigg)du \\
&= \Bigg(\frac{d\mathrm{atan2}}{dy}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_0 - \nabla u_1\big) + \frac{d\mathrm{atan2}}{dx}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_2 - \nabla u_3\big)\Bigg)^Tdu \\
\end{flalign*}
Therefore, we get that the gradient $\nabla \alpha\left(u\right)$ is given by:
\begin{equation}
\begin{split}
\nabla \alpha\left(u\right) = \frac{d\mathrm{atan2}}{dy}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_0 - \nabla u_1\big) + \\ \frac{d\mathrm{atan2}}{dx}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_2 - \nabla u_3\big)
\end{split}
\end{equation}
Where $\nabla u_0 - \nabla u_1 = \left(1,-1,0,0,0,0,0,0\right)^T$ and $\nabla u_2 - \nabla u_3 = \left(0,0,1,-1,0,0,0,0\right)^T$, $\nabla \mathrm{atan2}\left(y,x\right) = \left(\frac{-y}{x^2+y^2}, \frac{x}{x^2 + y^2}\right)^T$ and thus $\frac{d\mathrm{atan2}}{dy}\left(y,x\right) = \frac{-y}{x^2+y^2}$ and $\frac{d\mathrm{atan2}}{dx}\left(y,x\right) = \frac{x}{x^2+y^2}$.
The gradient $\nabla\beta\left(x\right)$ is derived in a similar way.
\subsection{Hessian}
The differential of $\nabla \h\left(u\right)$ is derived as follows:
\begin{flalign}
d \nabla h \left(u\right) &= d\Big(\nabla\alpha\left(u\right) - \nabla\beta\left(u\right)\Big)
\\
& = \nabla^2\alpha\left(u\right) du - \nabla^2\beta\left(u\right) du
\\
\label{eq:hessian_h_angle}
& = \Big(\nabla^2\alpha\left(u\right) - \nabla^2\beta\left(u\right)\Big) du
\end{flalign}
By \ref{eq:hessian_h_angle} we get that the gradient $\nabla^2 h\left(u\right)$ is given by:
\begin{equation}
\begin{split}
\nabla^2 h\left(u\right) = \nabla^2\alpha\left(u\right) - \nabla^2\beta\left(u\right)
\end{split}
\end{equation}
The differential of $\nabla \alpha\left(u\right)$ is derived as follows:
\begin{flalign}
d \nabla \alpha\left(u\right) &= d \Big( \frac{d\mathrm{atan2}}{dy}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_0 - \nabla u_1\big) + \\
\notag
& \quad \quad \frac{d\mathrm{atan2}}{dx}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_2 - \nabla u_3\big) \Big)
\\
&= d \frac{d\mathrm{atan2}}{dy}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_0 - \nabla u_1\big) + \\
\notag
& \quad \quad d \frac{d\mathrm{atan2}}{dx}\Big(u_0 - u_1, u_2 - u_3\Big) \big(\nabla u_2 - \nabla u_3\big)
\\
&= \bigg(\frac{d^2\mathrm{atan2}}{dy^2}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot d\left(u_0 - u_1\right) + \\
\notag
&\quad \quad \frac{d^2\mathrm{atan2}}{dxdy}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot d\left(u_2 - u_3\right)\bigg) \big(\nabla u_0 - \nabla u_1\big) + \\
\notag
&\quad \bigg(\frac{d^2\mathrm{atan2}}{dx^2}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot d\left(u_0 - u_1\right) + \\
\notag
&\quad \quad \frac{d^2\mathrm{atan2}}{dydx}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot d\left(u_2 - u_3\right)\bigg) \big(\nabla u_2 - \nabla u_3\big)
\\
&= \bigg(\frac{d^2\mathrm{atan2}}{dy^2}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \left(\nabla u_0 - \nabla u_1\right)^T du + \\
\notag
&\quad \quad \frac{d^2\mathrm{atan2}}{dxdy}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \left(\nabla u_2 - \nabla u_3\right)^T du \bigg) \big(\nabla u_0 - \nabla u_1\big) + \\
\notag
&\quad \bigg(\frac{d^2\mathrm{atan2}}{dx^2}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \left(\nabla u_0 - \nabla u_1\right)^T du + \\
\notag
&\quad \quad \frac{d^2\mathrm{atan2}}{dydx}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \left(\nabla u_2 - \nabla u_3\right)^T du \bigg) \big(\nabla u_2 - \nabla u_3\big)
\\
\label{eq:hessian_alpha_angle}
&= \bigg(\frac{d^2\mathrm{atan2}}{dy^2}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \big(\nabla u_0 - \nabla u_1\big) \left(\nabla u_0 - \nabla u_1\right)^T + \\
\notag
&\quad \quad \frac{d^2\mathrm{atan2}}{dxdy}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \big(\nabla u_0 - \nabla u_1\big) \left(\nabla u_2 - \nabla u_3\right)^T + \\
\notag
&\quad \quad \frac{d^2\mathrm{atan2}}{dx^2}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \big(\nabla u_2 - \nabla u_3\big) \left(\nabla u_0 - \nabla u_1\right)^T + \\
\notag
&\quad \quad \frac{d^2\mathrm{atan2}}{dydx}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \big(\nabla u_2 - \nabla u_3\big) \left(\nabla u_2 - \nabla u_3\right)^T \bigg) du
\end{flalign}
By \ref{eq:hessian_alpha_angle} we get that the Hessian $\nabla^2 \alpha\left(u\right)$ is given by:
\begin{equation}
\begin{split}
\nabla^2 \alpha\left(u\right) &= 
\frac{d^2\mathrm{atan2}}{dy^2}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \big(\nabla u_0 - \nabla u_1\big) \left(\nabla u_0 - \nabla u_1\right)^T + \\
\notag
&\quad \quad \frac{d^2\mathrm{atan2}}{dxdy}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \big(\nabla u_0 - \nabla u_1\big) \left(\nabla u_2 - \nabla u_3\right)^T + \\
\notag
&\quad \quad \frac{d^2\mathrm{atan2}}{dx^2}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \big(\nabla u_2 - \nabla u_3\big) \left(\nabla u_0 - \nabla u_1\right)^T + \\
\notag
&\quad \quad \frac{d^2\mathrm{atan2}}{dydx}\Big(u_0 - u_1, u_2 - u_3\Big) \cdot \big(\nabla u_2 - \nabla u_3\big) \left(\nabla u_2 - \nabla u_3\right)^T
\end{split}
\end{equation}
Where $\nabla u_0 - \nabla u_1 = \left(1,-1,0,0,0,0,0,0\right)^T$ and $\nabla u_2 - \nabla u_3 = \left(0,0,1,-1,0,0,0,0\right)^T$, $\nabla \mathrm{atan2}\left(y,x\right) = \left(\frac{-y}{x^2+y^2}, \frac{x}{x^2 + y^2}\right)^T$. The second partial derivatives of $\mathrm{atan2}$ can be easily derived by hand.
The Hessian $\nabla\beta\left(x\right)$ is derived in a similar way.
\section{Length Penalty Function}
We define the length penalty function $P_{length}$ as follows:
\begin{equation}\label{length_penalty}
\begin{split}
P_{\mathrm{length}}\left(e_i,e_j\right) = \left(\norm{e_i}_2^2 - \norm{e_j}_2^2\right)^2
\end{split}
\end{equation}
The length penalty measures the Euclidean length discrepancy between the two half-edges $e_i$ and $e_j$, where for $k \in \left\{i,j\right\}$, we have $e_k = \left(v^1_k, v^2_k\right)$ and therefore:
\begin{flalign}
\norm{e_k}_2^2 &= \left(v^2_k - v^1_k\right)^T\left(v^2_k - v^1_k\right) \\
&= \Big(\mathrm{x}\left(v_k^2\right) - \mathrm{x}\left(v_k^1\right), \mathrm{y}\left(v_k^2\right) - \mathrm{y}\left(v_k^1\right) \Big)^T \Big(\mathrm{x}\left(v_k^2\right) - \mathrm{x}\left(v_k^1\right), \mathrm{y}\left(v_k^2\right) - \mathrm{y}\left(v_k^1\right) \Big)
\end{flalign}
\noindent By denoting:
\begin{equation}\label{eq:angle_penalty}
u = \Big(\mathrm{y}\left(v_i^2\right), \mathrm{y}\left(v_i^1\right), \mathrm{x}\left(v_i^2\right), \mathrm{x}\left(v_i^1\right), \mathrm{y}\left(v_j^2\right), \mathrm{y}\left(v_j^1\right), \mathrm{x}\left(v_j^2\right), \mathrm{x}\left(v_j^1\right)\Big)^T
\end{equation}
And by replacing the sine expression with a piece-wise polynomial periodic function $f_p$ with period $p=\frac{\pi}{2}$ (as defined in appendix \ref{appendix:a}), we can rewrite $P_{\mathrm{angle}}$ as follows: